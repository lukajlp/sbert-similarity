{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116386,"databundleVersionId":13893386,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Configs e Imports\n","metadata":{}},{"cell_type":"code","source":"# instalar para o kaggle\n%pip install sentence-transformers datasets accelerate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q --upgrade wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# BIBLIOTECAS DE ANÁLISE DE DADOS E NUMÉRICAS\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\n\n# BIBLIOTECAS DE VISUALIZAÇÃO DE DADOS\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# BIBLIOTECAS DE MACHINE LEARNING E ESTATÍSTICA\nfrom scipy.stats import spearmanr\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n# BIBLIOTECA PRINCIPAL DE DEEP LEARNING (PYTORCH)\nimport torch\n\n# BIBLIOTECA DE NLP (SENTENCE TRANSFORMERS)\nfrom sentence_transformers import (\n    InputExample,  # Estrutura para encapsular um exemplo de treino (par de frases + label).\n    SentenceTransformer,  # Classe principal para carregar e usar modelos SBERT.\n    losses,  # Módulo com as funções de perda (ex: CosineSimilarityLoss).\n    util,  # Funções utilitárias (ex: util.cos_sim para similaridade).\n)\nfrom sentence_transformers.evaluation import (\n    EmbeddingSimilarityEvaluator,\n)  # Classe para avaliar a performance durante o treino.\nfrom sentence_transformers.similarity_functions import (\n    SimilarityFunction,\n)  # Enum para funções de similaridade (ex: COSINE).\nfrom sentence_transformers.trainer import (\n    SentenceTransformerTrainer,\n)  # API de alto nível para gerenciar o treinamento.\nfrom sentence_transformers.training_args import (\n    SentenceTransformerTrainingArguments,\n)  # Argumentos e configurações para o Trainer.\n\n# Define se o código rodará em GPU (cuda) ou CPU, otimizando a performance.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Usando device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport wandb\n\nuser_secrets = UserSecretsClient()\nwandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\nwandb.login(key=wandb_api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T21:28:55.025154Z","iopub.execute_input":"2025-10-04T21:28:55.025464Z","iopub.status.idle":"2025-10-04T21:28:55.149539Z","shell.execute_reply.started":"2025-10-04T21:28:55.025438Z","shell.execute_reply":"2025-10-04T21:28:55.148843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA\n","metadata":{}},{"cell_type":"code","source":"caminho_train = \"/kaggle/input/2025-2-similaridade-de-sentencas/train.csv\"\ncaminho_test = \"/kaggle/input/2025-2-similaridade-de-sentencas/test.csv\"\n\ndf = pd.read_csv(caminho_train)\nprint(\"Arquivo train.csv carregado com sucesso!\")\n\n# Exibir as primeiras linhas e informações básicas\nprint(\"\\nDimensões do DataFrame:\", df.shape)\nprint(\"\\nColunas disponíveis:\", df.columns.tolist())\nprint(\"\\nPrimeiras 3 linhas do DataFrame:\")\nprint(df.head(3))\n\nprint(\"\\nValores nulos por coluna:\")\nprint(df.isnull().sum())\n\n# Análise de Balanceamento das Classes\nprint(\"\\nDistribuição das classes:\")\nprint(df[\"similarity_score\"].value_counts().sort_index())\n\nprint(\"\\nEstatísticas do similarity_score:\")\nprint(df[\"similarity_score\"].describe())\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.hist(df[\"similarity_score\"], bins=20, alpha=0.7)\nplt.title(\"Distribuição dos Scores de Similaridade\")\nplt.xlabel(\"Similarity Score\")\nplt.ylabel(\"Frequência\")\n\nplt.subplot(1, 2, 2)\nsns.boxplot(y=df[\"similarity_score\"])\nplt.title(\"Boxplot dos Scores de Similaridade\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preparando Dados para o SBERT\n","metadata":{}},{"cell_type":"code","source":"# Separar X e y\nX = df[[\"sentence1\", \"sentence2\"]]\ny = df[\"similarity_score\"]\n\n# Separar dados em treino e validação\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Normalizar os scores para o intervalo [0, 1]\ny_train_norm = y_train / 5.0\ny_val_norm = y_val / 5.0\n\n# Verificar os resultados\nprint(\"\\nDimensões do conjunto de treino:\", X_train.shape)\nprint(\"Dimensões do conjunto de validação:\", X_val.shape)\nprint(\"\\nDistribuição das classes no conjunto de treino:\")\nprint(y_train.value_counts().sort_index())\nprint(\"\\nDistribuição das classes no conjunto de validação:\")\nprint(y_val.value_counts().sort_index())\n\n# Preparar dados como Dataset do Hugging Face\ntrain_dataset = Dataset.from_dict({\n    \"sentence1\": X_train[\"sentence1\"].tolist(),\n    \"sentence2\": X_train[\"sentence2\"].tolist(),\n    \"label\": y_train_norm.tolist()\n})\n\nval_dataset = Dataset.from_dict({\n    \"sentence1\": X_val[\"sentence1\"].tolist(),\n    \"sentence2\": X_val[\"sentence2\"].tolist(),\n    \"label\": y_val_norm.tolist()\n})\n\n# Preparando Dados para o SBERT\ntrain_examples = [\n    InputExample(texts=[s1, s2], label=float(label))\n    for s1, s2, label in zip(X_train[\"sentence1\"], X_train[\"sentence2\"], y_train_norm)\n]\n\nval_examples = [\n    InputExample(texts=[s1, s2], label=float(label))\n    for s1, s2, label in zip(X_val[\"sentence1\"], X_val[\"sentence2\"], y_val)\n]\n\nprint(f\"\\nNúmero de exemplos de treino: {len(train_examples)}\")\nprint(f\"Número de exemplos de validação: {len(val_examples)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Configuração do Modelo SBERT\n","metadata":{}},{"cell_type":"code","source":"# Configurar modelo\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\nmodel = model.to(device)\n\n# Configurar loss function\ntrain_loss = losses.CosineSimilarityLoss(model=model)\n\n# Configurar avaliador\ndev_evaluator = EmbeddingSimilarityEvaluator(\n    sentences1=[example.texts[0] for example in val_examples],\n    sentences2=[example.texts[1] for example in val_examples],\n    scores=[example.label for example in val_examples],\n    main_similarity=SimilarityFunction.COSINE,\n    show_progress_bar=True,\n    name=\"validation\",\n)\n\nprint(\"Modelo e avaliador configurados com sucesso!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Treinamento do Modelo\n","metadata":{}},{"cell_type":"code","source":"num_epochs = 4\nbatch_size = 16","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configurar argumentos de treinamento\nargs = SentenceTransformerTrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=num_epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    warmup_ratio=0.1,\n    fp16=True,\n    eval_strategy=\"steps\",\n    eval_steps=100,\n    save_strategy=\"steps\",\n    save_steps=100,\n    save_total_limit=2,\n    logging_steps=100,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_validation_spearman_cosine\",\n    greater_is_better=True,\n    run_name=\"sbert-similarity-training\",\n)\n\n# Configurar trainer\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    loss=train_loss,\n    evaluator=dev_evaluator,\n)\n\nprint(\"Trainer configurado. Iniciando treinamento...\")\n\n# Treinar o modelo\ntrainer.train()\n\nprint(\"Treinamento concluído!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Avaliação do Modelo\n","metadata":{}},{"cell_type":"code","source":"# Salvar o modelo treinado\ncaminho_modelo = \"./fine-tuned-sbert-model\"\nmodel.save(caminho_modelo)\nprint(\"Modelo salvo!\")\n\n# Avaliar no conjunto de validação\nprint(\"\\nAvaliação no conjunto de validação:\")\nval_score = dev_evaluator(model)\nmain_score = val_score[dev_evaluator.primary_metric]\n\nprint(f\"Validation Score: {main_score:.4f}\") \n\nprint(\"\\nIniciando avaliação manual detalhada...\")\n\n# Gerar embeddings para as sentenças de validação\nval_embeddings1 = model.encode(\n    [example.texts[0] for example in val_examples],\n    show_progress_bar=True,\n    device=device,\n)\nval_embeddings2 = model.encode(\n    [example.texts[1] for example in val_examples],\n    show_progress_bar=True,\n    device=device,\n)\n\n# Calcular similaridade coseno\nsimilarities = util.cos_sim(val_embeddings1, val_embeddings2)\n\nval_predictions = [similarities[i][i] for i in range(len(similarities))]\n\n# Valores verdadeiros\nval_true = np.array([example.label for example in val_examples])\nval_true_norm = val_true / 5.0\n\n# Métricas\nmse = mean_squared_error(val_true_norm, val_predictions)\nmae = mean_absolute_error(val_true_norm, val_predictions)\n\n# Calcule as correlações\npearson_corr = np.corrcoef(val_true, val_predictions)[0, 1]\nspearman_corr, _ = spearmanr(val_true, val_predictions)\n\n\nprint(\"\\nMétricas de Validação Detalhadas:\")\nprint(f\"MSE (comparando 0-1 vs 0-1): {mse:.4f}\")\nprint(f\"MAE (comparando 0-1 vs 0-1): {mae:.4f}\")\nprint(\"-\" * 30)\nprint(f\"Pearson Correlation: {pearson_corr:.4f}\")\nprint(f\"Spearman Correlation (manual): {spearman_corr:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Teste no Conjunto de Teste\n","metadata":{}},{"cell_type":"code","source":"caminho_submissao = \"./submission.csv\"\n\nprint(f\"Lendo dados de teste de '{caminho_test}'...\")\ndf_test = pd.read_csv(caminho_test)\n\n# Extrair as sentenças e os índices para o arquivo de submissão\ntest_sentences1 = df_test[\"sentence1\"].tolist()\ntest_sentences2 = df_test[\"sentence2\"].tolist()\ntest_indexes = df_test.iloc[:, 0].tolist()\nprint(f\"Encontrados {len(df_test)} exemplos no conjunto de teste.\")\n\n\n# --- 4. Gerar Predições ---\nprint(\"Gerando embeddings e calculando similaridade...\")\n\n# Gerar embeddings (o modelo processa tudo em lote, é muito eficiente)\nembeddings1 = model.encode(test_sentences1, show_progress_bar=True, device=device)\nembeddings2 = model.encode(test_sentences2, show_progress_bar=True, device=device)\n\n# Calcular similaridade de cosseno para todos os pares de uma vez\ntest_similarities = util.cos_sim(embeddings1, embeddings2)\n\n# As predições são a diagonal da matriz de similaridade (score de 0-1)\npredictions_normalized = [\n    test_similarities[i][i] for i in range(len(test_similarities))\n]\nprint(\"Predições na escala 0-1 calculadas.\")\n\n# O modelo prevê na escala 0-1. O arquivo de submissão precisa da escala 0-5.\nprint(\"Reescalonando predições para a escala 0-5...\")\npredictions_rescaled = np.array(predictions_normalized) * 5.0\n\n# Garante que nenhum valor fique fora da faixa 0-5\npredictions_rescaled = np.clip(predictions_rescaled, 0, 5)\n\n\n# Criar e Salvar o Arquivo de Submissão\nprint(\"Criando o DataFrame de submissão...\")\nsubmission_df = pd.DataFrame(\n    {\"index\": test_indexes, \"predictions\": predictions_rescaled}\n)\n\n# Salvar no formato CSV sem o índice do pandas\nsubmission_df.to_csv(caminho_submissao, index=False)\nprint(f\"Arquivo de submissão salvo com sucesso em: {caminho_submissao}\")\n\n# Verificação final\nprint(\"\\nPrimeiras 5 linhas do arquivo de submissão:\")\nprint(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizar resultados\nplt.figure(figsize=(18, 5))\n\n# Gráfico 1: Scatter Plot (True vs Predicted na escala 0-1)\nplt.subplot(1, 3, 1)\nplt.scatter(val_true_norm, val_predictions, alpha=0.6)\nplt.plot([0, 1], [0, 1], \"r--\")\nplt.xlabel(\"True Similarity\")\nplt.ylabel(\"Predicted Similarity\")\nplt.title(\"Validação: True vs Predicted (0-1)\")\nplt.grid(True)\n\n# Gráfico 2: Histogramas de Distribuição (Validação, na escala 0-1)\nplt.subplot(1, 3, 2)\nplt.hist(val_predictions, bins=20, alpha=0.7, label=\"Predicted\", density=True)\nplt.hist(val_true_norm, bins=20, alpha=0.7, label=\"True\", density=True)\nplt.xlabel(\"Similarity Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribuição - Validação (0-1)\")\nplt.legend()\n\n# Gráfico 3: Histograma de Distribuição (Teste, na escala 0-1)\nplt.subplot(1, 3, 3)\nplt.hist(predictions_normalized, bins=20, alpha=0.7, color=\"green\")\nplt.xlabel(\"Similarity Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribuição - Teste (0-1)\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Análise completa!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}